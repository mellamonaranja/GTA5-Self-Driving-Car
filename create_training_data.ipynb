{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from grabscreen import grab_screen\n",
    "import cv2\n",
    "import time\n",
    "from getkeys import key_check\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (410980490.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    prediction = [2.7295275e-07 9.5072293e-01 2.3666177e-02 2.5610570e-02]\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "prediction = [2.7295275e-07, 9.5072293e-01, 2.3666177e-02, 2.5610570e-02]\n",
    "\n",
    "# Convert the prediction list to a NumPy array for easier manipulation\n",
    "prediction_array = np.array(prediction)\n",
    "\n",
    "# Calculate the average of the values in the prediction array\n",
    "average_prediction = np.mean(prediction_array)\n",
    "\n",
    "print(\"Average of prediction:\", average_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "prediction = [2.7295275e-07, 9.5072293e-01, 2.3666177e-02, 2.5610570e-02]\n",
    "print(all(value < 1 for value in prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "keys = ['A', 'W', 'D', 'S', 'WA', 'WD', 'SA', 'SD', 'NO_KEY']\n",
    "output = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# Define a dictionary to map keys to their corresponding indices in the output list\n",
    "key_to_index = {'A': 0, 'W': 1, 'D': 2, 'S': 3, 'WA': 4, 'WD': 5, 'SA': 6, 'SD': 7, 'NO_KEY': 8}\n",
    "\n",
    "# Loop through the keys and set the corresponding indices in the output list to 1\n",
    "for key in keys:\n",
    "    if key in key_to_index:\n",
    "        output[key_to_index[key]] = 1\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keys_to_output(keys):\n",
    "    keys = ['A', 'W', 'D', 'S', 'WA', 'WD', 'SA', 'SD', 'NO_KEY']\n",
    "    output = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "    # Define a dictionary to map keys to their corresponding indices in the output list\n",
    "    key_to_index = {'A': 0, 'W': 1, 'D': 2, 'S': 3, 'WA': 4, 'WD': 5, 'SA': 6, 'SD': 7, 'NO_KEY': 8}\n",
    "\n",
    "    # Loop through the keys and set the corresponding indices in the output list to 1\n",
    "    for key in keys:\n",
    "        if key in key_to_index:\n",
    "            output[key_to_index[key]] = 1\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_to_output(['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def keys_to_output(keys):\n",
    "    # Remove the keys initialization from here\n",
    "    output = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "    # Define a dictionary to map keys to their corresponding indices in the output list\n",
    "    key_to_index = {'A': 0, 'W': 1, 'D': 2, 'S': 3, 'WA': 4, 'WD': 5, 'SA': 6, 'SD': 7, 'NO_KEY': 8}\n",
    "\n",
    "    # Loop through the keys and set the corresponding indices in the output list to 1\n",
    "    for key in keys:\n",
    "        if key in key_to_index:\n",
    "            output[key_to_index[key]] = 1\n",
    "\n",
    "    return output\n",
    "\n",
    "# Test the function with different input keys\n",
    "print(keys_to_output(['A']))\n",
    "print(keys_to_output(['W']))\n",
    "\n",
    "print(keys_to_output('W'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keys_to_output(key):\n",
    "    output = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    key_to_index = {'A': 0, 'W': 1, 'D': 2, 'S': 3, 'WA': 4, 'WD': 5, 'SA': 6, 'SD': 7, 'NO_KEY': 8}\n",
    "    if key in key_to_index:\n",
    "        output[key_to_index[key]] = 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_to_output('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_output(output):\n",
    "    for i in range(1,len(output)):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output counts: Counter({1: 5, 0: 4})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_output(output):\n",
    "    # Use Counter to count occurrences of each value in the output list\n",
    "    output_counts = Counter(output)\n",
    "    return output_counts\n",
    "\n",
    "# Test the function with an example output\n",
    "example_output = [0, 1, 1, 0, 1, 0, 0, 1, 1]\n",
    "output_counts = count_output(example_output)\n",
    "print(\"Output counts:\", output_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n",
      "[1, 2, 3, 4, 5]\n",
      "[1, 2, 3, 4, 5]\n",
      "[1, 2, 3, 4, 5]\n",
      "[1, 2, 3, 4, 5]\n",
      "[1, 2, 3, 4, 5]\n",
      "[1, 2, 3, 4, 5]\n",
      "[1, 2, 3, 4, 5]\n",
      "[1, 2, 3, 4, 5]\n",
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "for e in range(10):\n",
    "    data_order=[i for i in range(1,5+1)] \n",
    "    print(data_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 4, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "data_order = [i for i in range(1, 5+1)]\n",
    "\n",
    "# Shuffle the data_order list\n",
    "random.shuffle(data_order)\n",
    "\n",
    "print(data_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keys_to_output(keys):\n",
    "    output = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    key_to_index = {'A': 0, 'W': 1, 'D': 2, 'S': 3, 'WA': 4, 'WD': 5, 'SA': 6, 'SD': 7, 'NO_KEY': 8}\n",
    "    \n",
    "    # If keys is a list, process each key\n",
    "    if isinstance(keys, list):\n",
    "        for key in keys:\n",
    "            if key in key_to_index:\n",
    "                output[key_to_index[key]] = 1\n",
    "    # If keys is a single key string, process it directly\n",
    "    elif isinstance(keys, str):\n",
    "        if keys in key_to_index:\n",
    "            output[key_to_index[keys]] = 1\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [1,0,0,0,0,0,0,0,0]\n",
    "s = [0,1,0,0,0,0,0,0,0]\n",
    "a = [0,0,1,0,0,0,0,0,0]\n",
    "d = [0,0,0,1,0,0,0,0,0]\n",
    "wa = [0,0,0,0,1,0,0,0,0]\n",
    "wd = [0,0,0,0,0,1,0,0,0]\n",
    "sa = [0,0,0,0,0,0,1,0,0]\n",
    "sd = [0,0,0,0,0,0,0,1,0]\n",
    "nk = [0,0,0,0,0,0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keys_to_output1(keys):\n",
    "    '''\n",
    "    Convert keys to a ...multi-hot... array\n",
    "     0  1  2  3  4   5   6   7    8\n",
    "    [W, S, A, D, WA, WD, SA, SD, NOKEY] boolean values.\n",
    "    '''\n",
    "    output = [0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "    if 'W' in keys and 'A' in keys:\n",
    "        output = wa\n",
    "    elif 'W' in keys and 'D' in keys:\n",
    "        output = wd\n",
    "    elif 'S' in keys and 'A' in keys:\n",
    "        output = sa\n",
    "    elif 'S' in keys and 'D' in keys:\n",
    "        output = sd\n",
    "    elif 'W' in keys:\n",
    "        output = w\n",
    "    elif 'S' in keys:\n",
    "        output = s\n",
    "    elif 'A' in keys:\n",
    "        output = a\n",
    "    elif 'D' in keys:\n",
    "        output = d\n",
    "    else:\n",
    "        output = nk\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_to_output1('W')==keys_to_output('W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_to_output('W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\motoko\\AppData\\Local\\Temp\\ipykernel_12464\\1691378235.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train=np.array(([[145, 255, 255, ..., 255, 255, 255],\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train=np.array(([[145, 255, 255, ..., 255, 255, 255],\n",
    "        [145, 255, 255, ..., 255, 255, 255],\n",
    "        [145, 190, 190, ..., 179, 179, 179],\n",
    "        ...,\n",
    "        [149,  56,  58, ..., 130, 225, 130],\n",
    "        [150,  53,  54, ..., 136,  67, 127],\n",
    "        [149,  55,  55, ...,  93, 129,  94]], ([0, 0, 0, 0, 0, 0, 0, 0, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([145, 255, 255, Ellipsis, 255, 255, 255]) 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\motoko\\AppData\\Local\\Temp\\ipykernel_12464\\3204246738.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X=np.array([i[0] for i in train])\n"
     ]
    }
   ],
   "source": [
    "X=np.array([i[0] for i in train])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(train[0]))\n",
    "print(len(train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\motoko\\AppData\\Local\\Temp\\ipykernel_12464\\1501062495.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  print(np.array([i[0] for i in train]).reshape(-1,160,120,1))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2 into shape (160,120,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m160\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 2 into shape (160,120,1)"
     ]
    }
   ],
   "source": [
    "print(np.array([i[0] for i in train]).reshape(-1,160,120,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "for e in range(5):\n",
    "    data_order=[i for i in range(1,16)] \n",
    "    for count, i in enumerate(data_order):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keys_to_output(keys):\n",
    "    # Define output vector for three keys: A, W, D\n",
    "    output = [0, 0, 0]\n",
    "    # Mapping of keys to indices in the output vector\n",
    "    key_to_index = {'A': 0, 'W': 1, 'D': 2}\n",
    "    \n",
    "    # Check if keys is a list and process each key\n",
    "    if isinstance(keys, list):\n",
    "        for key in keys:\n",
    "            if key in key_to_index:\n",
    "                output[key_to_index[key]] = 1\n",
    "    # If keys is a single key string, process it directly\n",
    "    elif isinstance(keys, str):\n",
    "        if keys in key_to_index:\n",
    "            output[key_to_index[keys]] = 1\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keys_to_output(*args):\n",
    "    # Define output vector for three keys: A, W, D\n",
    "    output = [0, 0, 0]\n",
    "    # Mapping of keys to indices in the output vector\n",
    "    key_to_index = {'A': 0, 'W': 1, 'D': 2}\n",
    "    \n",
    "    # args will contain all arguments passed to the function\n",
    "    for key in args:\n",
    "        if key in key_to_index:\n",
    "            output[key_to_index[key]] = 1\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_to_output('W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (0,))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m target_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_010)\n\u001b[0;32m     40\u001b[0m augmented_110 \u001b[38;5;241m=\u001b[39m augment_class(data_110, [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m], target_count)\n\u001b[1;32m---> 41\u001b[0m augmented_011 \u001b[38;5;241m=\u001b[39m \u001b[43maugment_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_011\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Add augmented data back to the dataset\u001b[39;00m\n\u001b[0;32m     44\u001b[0m dataset\u001b[38;5;241m.\u001b[39mextend(augmented_110)\n",
      "Cell \u001b[1;32mIn[55], line 31\u001b[0m, in \u001b[0;36maugment_class\u001b[1;34m(data, label, target_count)\u001b[0m\n\u001b[0;32m     29\u001b[0m augmented_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     30\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     32\u001b[0m     augmented_data\u001b[38;5;241m.\u001b[39mappend([batch[\u001b[38;5;241m0\u001b[39m], label])\n\u001b[0;32m     33\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\motoko\\anaconda3\\envs\\GTA5AI\\lib\\site-packages\\keras\\preprocessing\\image.py:1545\u001b[0m, in \u001b[0;36mImageDataGenerator.flow\u001b[1;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, ignore_class_split, subset)\u001b[0m\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow\u001b[39m(\n\u001b[0;32m   1487\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1488\u001b[0m     x,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1499\u001b[0m ):\n\u001b[0;32m   1500\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Takes data & label arrays, generates batches of augmented data.\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \n\u001b[0;32m   1502\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1543\u001b[0m \n\u001b[0;32m   1544\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNumpyArrayIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1547\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1548\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_class_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_class_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\motoko\\anaconda3\\envs\\GTA5AI\\lib\\site-packages\\keras\\preprocessing\\image.py:758\u001b[0m, in \u001b[0;36mNumpyArrayIterator.__init__\u001b[1;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, ignore_class_split, dtype)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_misc \u001b[38;5;241m=\u001b[39m x_misc\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m--> 758\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    759\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput data in `NumpyArrayIterator` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    760\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould have rank 4. You passed an array \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    761\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith shape\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    762\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m    763\u001b[0m     )\n\u001b[0;32m    764\u001b[0m channels_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[channels_axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m}:\n",
      "\u001b[1;31mValueError\u001b[0m: ('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (0,))"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your dataset is a list of [image, label] pairs\n",
    "dataset = [\n",
    "    [np.random.rand(100, 100, 3), np.array([0, 1, 0])],\n",
    "    [np.random.rand(100, 100, 3), np.array([1, 1, 0])],\n",
    "    # Add more samples as per your dataset...\n",
    "]\n",
    "\n",
    "# Filter data by classes\n",
    "data_010 = [x[0] for x in dataset if np.array_equal(x[1], np.array([0, 1, 0]))]\n",
    "data_110 = [x[0] for x in dataset if np.array_equal(x[1], np.array([1, 1, 0]))]\n",
    "data_011 = [x[0] for x in dataset if np.array_equal(x[1], np.array([0, 1, 1]))]\n",
    "\n",
    "# Augmentation configuration for our data\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Function to augment a class dataset to the target number of samples\n",
    "def augment_class(data, label, target_count):\n",
    "    augmented_data = []\n",
    "    i = 0\n",
    "    for batch in datagen.flow(np.array(data), batch_size=1):\n",
    "        augmented_data.append([batch[0], label])\n",
    "        i += 1\n",
    "        if i >= (target_count - len(data)):\n",
    "            break\n",
    "    return augmented_data\n",
    "\n",
    "# Augment classes to match the count of the most frequent class\n",
    "target_count = len(data_010)\n",
    "augmented_110 = augment_class(data_110, [1, 1, 0], target_count)\n",
    "augmented_011 = augment_class(data_011, [0, 1, 1], target_count)\n",
    "\n",
    "# Add augmented data back to the dataset\n",
    "dataset.extend(augmented_110)\n",
    "dataset.extend(augmented_011)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your dataset is a list of [image, label] pairs\n",
    "dataset = [\n",
    "    [np.random.rand(100, 100, 3), np.array([0, 1, 0])],\n",
    "    [np.random.rand(100, 100, 3), np.array([1, 1, 0])],\n",
    "    # Add more samples as per your dataset...\n",
    "]\n",
    "\n",
    "# Filter data by classes\n",
    "data_010 = [x[0] for x in dataset if np.array_equal(x[1], np.array([0, 1, 0]))]\n",
    "data_110 = [x[0] for x in dataset if np.array_equal(x[1], np.array([1, 1, 0]))]\n",
    "data_011 = [x[0] for x in dataset if np.array_equal(x[1], np.array([0, 1, 1]))]\n",
    "\n",
    "# Augmentation configuration for our data\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Function to augment a class dataset to the target number of samples\n",
    "def augment_class(data, label, target_count):\n",
    "    augmented_data = []\n",
    "    if data:  # Check if data is not empty\n",
    "        i = 0\n",
    "        for batch in datagen.flow(np.array(data), batch_size=1):\n",
    "            augmented_data.append([batch[0], label])\n",
    "            i += 1\n",
    "            if i >= (target_count - len(data)):\n",
    "                break\n",
    "    return augmented_data\n",
    "\n",
    "# Augment classes to match the count of the most frequent class\n",
    "target_count = len(data_010)\n",
    "augmented_110 = augment_class(data_110, [1, 1, 0], target_count)\n",
    "augmented_011 = augment_class(data_011, [0, 1, 1], target_count)\n",
    "\n",
    "# Add augmented data back to the dataset\n",
    "dataset.extend(augmented_110)\n",
    "dataset.extend(augmented_011)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter:Counter({'[0 1 0]': 1, '[1 1 0]': 1, '[1, 1, 0]': 1})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dataset) \n",
    "print('counter:{}'.format(Counter(df[1].apply(str)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of '1 1 0' images: (100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "def augment_class(data, label, target_count):\n",
    "    augmented_data = []\n",
    "    if not data:\n",
    "        return augmented_data  # Return empty if no data to avoid errors\n",
    "    \n",
    "    data_np = np.array(data)  # Convert list to numpy array\n",
    "    if data_np.ndim == 3:  # Check if we need to expand dimensions\n",
    "        data_np = np.expand_dims(data_np, axis=0)\n",
    "\n",
    "    i = 0\n",
    "    for batch in datagen.flow(data_np, batch_size=1):\n",
    "        augmented_data.append([batch[0], label])\n",
    "        i += 1\n",
    "        if i >= (target_count - len(data)):\n",
    "            break\n",
    "    return augmented_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7, 8])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is: Wednesday\n",
      "Current time: 18:10:15\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# Get the current datetime\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Get the day of the week\n",
    "day_of_week = now.strftime(\"%A\")  # This will give you the full name of the day, e.g., \"Monday\"\n",
    "\n",
    "# Get the current time\n",
    "current_time = now.strftime(\"%H:%M:%S\")  # This will format the time as Hour:Minute:Second\n",
    "\n",
    "print(\"Today is:\", day_of_week)\n",
    "print(\"Current time:\", current_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Current time:\", current_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GTA5AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
