{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import ImageGrab\n",
    "import cv2\n",
    "import time\n",
    "from numpy import ones,vstack\n",
    "from numpy.linalg import lstsq\n",
    "from directkeys import PressKey, W, A, S, D\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bbox: _Box | None = None,\n",
    "    include_layered_windows: bool = False,\n",
    "    all_screens: bool = False,\n",
    "    xdisplay: None = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from directkeys import ReleaseKey, PressKey, W, A, S, D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def cvtColor(\n",
    "    src: MatLike,\n",
    "    code: int,\n",
    "    dst: MatLike | None = ...,\n",
    "    dstCn: int = ...\n",
    ") -> MatLike: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def screen_record():\n",
    "    last_time=time.time()\n",
    "    while(True):\n",
    "        printscreen=np.array(ImageGrab.grab(bbox=(0,45,800,650)))\n",
    "        print('loop took {} seconds'.format(time.time()-last_time))\n",
    "\n",
    "        last_time=time.time()\n",
    "        cv2.imshow('window',cv2.cvtColor(printscreen, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if cv2.waitKey(25) & 0xFF==ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.line(image, start_point, end_point, color, thickness) \n",
    "\n",
    "start_point: It is the starting coordinates of the line. The coordinates are represented as tuples of two values i.e. (X coordinate value, Y coordinate value). \n",
    "\n",
    "end_point: It is the ending coordinates of the line. The coordinates are represented as tuples of two values i.e. (X coordinate value, Y coordinate value). \n",
    "\n",
    "color: It is the color of the line to be drawn. For RGB, we pass a tuple. eg: (255, 0, 0) for blue color.\n",
    "\n",
    "thickness: It is the thickness of the line in px. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw_lines(img, lines):\n",
    "#     try:\n",
    "#         for line in lines:\n",
    "#         # lines=[[[2,3,2,3]]]\n",
    "#             coords=line[0] #[2, 3, 2, 3]\n",
    "#             cv2.line(img, (coords[0], coords[1]), (coords[2],coords[3]), (255,255,255),3) #coords[0]=2\n",
    "#     except:\n",
    "#         pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines=[[[2,3,2,3]]]\n",
    "# for line in lines:\n",
    "#     coords=line[0]\n",
    "#     print(coords[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.zeros_like\n",
    "\n",
    "x = np.arange(6)\n",
    "x = x.reshape((2, 3))\n",
    "x\n",
    ">>>\n",
    "array([[0, 1, 2],\n",
    "       [3, 4, 5]])\n",
    "np.zeros_like(x)\n",
    "array([[0, 0, 0],\n",
    "       [0, 0, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.fillPoly(img,pts,color)\n",
    "\n",
    "Paint one or more polygons in color.\n",
    "pts : points, an np polygonal arrangement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.bitwise_and(source1, source2, destination, mask)\n",
    "\n",
    "Bit-wise conjunction of input array elements. overlay things\n",
    "\n",
    "source1: First Input Image array(Single-channel, 8-bit or floating-point) </br>\n",
    "source2: Second Input Image array(Single-channel, 8-bit or floating-point) </br>\n",
    "dest: Output array (Similar to the dimensions and type of Input image array) </br>\n",
    "mask: Operation mask, Input / output 8-bit single-channel mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines=[[[2,3,2,3]]]\n",
    "\n",
    "# for inx, i in enumerate(lines):\n",
    "#     for xyxy in i:\n",
    "#         x_coords=(xyxy[0], xyxy[2])\n",
    "#         y_coords=(xyxy[1], xyxy[3])\n",
    "#         # print(x_coords)\n",
    "\n",
    "# A=np.vstack([x_coords, np.ones(len(x_coords))]).T\n",
    "\n",
    "# # x_coords\n",
    "# # print(np.linalg.lstsq(A, y_coords))\n",
    "# # print(np.linalg.lstsq(A, y_coords)[:])\n",
    "# print(np.linalg.lstsq(A, y_coords)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "printscreen_pil.getdata\n",
    "\n",
    "Returns the contents of this image as a sequence object containing pixel values. The sequence object is flattened, so that values for line one follow directly after the values of line zero, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.Canny(gray_img, threshold1, threshold2)\n",
    "\n",
    "an edge detection algorithm\n",
    "\n",
    "(input image, minVal, maxVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.HoughLines(img, rho, theta, threshold)\n",
    "\n",
    "detect any shape\n",
    "\n",
    "img : a grayscale image\n",
    "rho is measured in pixels \n",
    "theta is measured in radians\n",
    "threshold : minimum vote it should get for it to be considered as a line. it represents the minimum length of line that should be detected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.HoughLinesP(img, rho, theta, threshold, minLineLength,maxLineGap)\n",
    "\n",
    "optimization of HoughLines\n",
    "\n",
    "It doesnâ€™t take all the points into consideration, instead take only a random subset of points and that is sufficient for line detection. \n",
    "\n",
    "minLineLength : Minimum length of line. Line segments shorter than this are rejected. how long should this line\n",
    "maxLineGap - Maximum allowed gap between line segments to treat them as single line. how much gap you allow between line and line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GaussianBlur(img, output_img, ksize, sigmaX,sigmaY)\n",
    "\n",
    "Blurs an image using a Gaussian filter.\n",
    "\n",
    "ksize : Gaussian kernel size. ksize.width and ksize.height can differ but they both must be positive and odd.\n",
    "\n",
    "sigmaX : Gaussian kernel standard deviation in X direction.\n",
    "\n",
    "sigmaY : Gaussian kernel standard deviation in Y direction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyAutoGUI lets your Python scripts control the mouse and keyboard to automate interactions with other applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python sleep() is a function used to delay the execution of code for the number of seconds given as input to sleep(). The sleep() command is a part of the time module. You can use the sleep() function to temporarily halt the execution of your code. For example, you are waiting for a process to complete or a file upload."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def keyDown(\n",
    "    key: str,\n",
    "    logScreenshot: bool | None = None,\n",
    "    _pause: bool = True\n",
    ") -> None\n",
    "Performs a keyboard key press without the release. This will put that key in a held down state.\n",
    "\n",
    "NOTE: For some reason, this does not seem to cause key repeats like would happen if a keyboard key was held down on a text field.\n",
    "\n",
    "Args:\n",
    "  key (str): The key to be pressed down. The valid names are listed in KEYBOARD_KEYS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so my goal with\n",
    "where we're going right now is to either\n",
    "Goal\n",
    "create an AI that can drive already\n",
    "based on some simple rules that we set\n",
    "with open CV that can hopefully at least\n",
    "drive on it you know just straight it'll\n",
    "basically know turning and stuff like\n",
    "that node going through intersections\n",
    "just kind of drive along a road like\n",
    "this and hopefully navigate the turn-up\n",
    "ahead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ones,vstack\n",
    "from numpy.linalg import lstsq\n",
    "\n",
    "def roi(img, vertices):\n",
    "    \n",
    "    #blank mask:\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, 255)\n",
    "    \n",
    "    #only the ROI is left, only show the area that is the mask\n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked = cv2.bitwise_and(img, mask)\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lanes(img, lines, color=[255, 0, 0], thickness=1):\n",
    "\n",
    "    # if this fails, go with some default line\n",
    "    try:\n",
    "\n",
    "        # finds the maximum y value for a lane marker \n",
    "        # (since we cannot assume the horizon will always be at the same point.)\n",
    "\n",
    "        ys = []  \n",
    "        for i in lines:# lines=[[[2,3,2,3]]], i=[[2, 3, 2, 3]], ii=[2, 3, 2, 3]\n",
    "            for ii in i:\n",
    "                ys += [ii[1],ii[3]]\n",
    "\n",
    "        # min y : the furthest up to the horizon, it will find the lane up to the horizon base there any line, the highest point for any line\n",
    "        min_y = min(ys)\n",
    "        max_y = 600\n",
    "        new_lines = []\n",
    "        line_dict = {}\n",
    "\n",
    "        for idx,i in enumerate(lines):\n",
    "            for xyxy in i:#xyxy=[2, 3, 2, 3]\n",
    "                # These four lines:\n",
    "                # modified from http://stackoverflow.com/questions/21565994/method-to-return-the-equation-of-a-straight-line-given-two-points\n",
    "                # Used to calculate the definition of a line, given two sets of coords.\n",
    "                x_coords = (xyxy[0],xyxy[2])#x_coords=(2,2)\n",
    "                y_coords = (xyxy[1],xyxy[3])\n",
    "                A = vstack([x_coords,ones(len(x_coords))]).T #array([[2., 2.], [1., 1.]])-->T : array([[2., 1.], [2., 1.]])\n",
    "                m, b = lstsq(A, y_coords)[0]\n",
    "\n",
    "                # Calculating our new, and improved, xs\n",
    "                x1 = (min_y-b) / m\n",
    "                x2 = (max_y-b) / m\n",
    "\n",
    "                line_dict[idx] = [m,b,[int(x1), min_y, int(x2), max_y]]\n",
    "                new_lines.append([int(x1), min_y, int(x2), max_y])\n",
    "\n",
    "        final_lanes = {}\n",
    "\n",
    "        for idx in line_dict:\n",
    "            final_lanes_copy = final_lanes.copy()\n",
    "            m = line_dict[idx][0]\n",
    "            b = line_dict[idx][1]\n",
    "            line = line_dict[idx][2]\n",
    "            \n",
    "            if len(final_lanes) == 0:\n",
    "                final_lanes[m] = [ [m,b,line] ]\n",
    "                \n",
    "            else:\n",
    "                found_copy = False\n",
    "\n",
    "                for other_ms in final_lanes_copy:\n",
    "\n",
    "                    if not found_copy:\n",
    "                        #bias of the two lines, within +-20% assume that's the same line\n",
    "                        if abs(other_ms*1.2) > abs(m) > abs(other_ms*0.8):\n",
    "                            #bias of the two lines, within +-20% assume that's the same line\n",
    "                            if abs(final_lanes_copy[other_ms][0][1]*1.2) > abs(b) > abs(final_lanes_copy[other_ms][0][1]*0.8):\n",
    "                                final_lanes[other_ms].append([m,b,line])\n",
    "                                found_copy = True\n",
    "                                break\n",
    "                        else:\n",
    "                            final_lanes[m] = [ [m,b,line] ]\n",
    "\n",
    "        line_counter = {}\n",
    "\n",
    "        for lanes in final_lanes:\n",
    "            line_counter[lanes] = len(final_lanes[lanes])\n",
    "\n",
    "        top_lanes = sorted(line_counter.items(), key=lambda item: item[1])[::-1][:2]\n",
    "\n",
    "        #slopes\n",
    "        lane1_id = top_lanes[0][0]\n",
    "        lane2_id = top_lanes[1][0]\n",
    "\n",
    "        def average_lane(lane_data):\n",
    "            x1s = []\n",
    "            y1s = []\n",
    "            x2s = []\n",
    "            y2s = []\n",
    "            for data in lane_data:\n",
    "                x1s.append(data[2][0])\n",
    "                y1s.append(data[2][1])\n",
    "                x2s.append(data[2][2])\n",
    "                y2s.append(data[2][3])\n",
    "            return int(mean(x1s)), int(mean(y1s)), int(mean(x2s)), int(mean(y2s)) \n",
    "\n",
    "        #find the two final most common slopes\n",
    "        l1_x1, l1_y1, l1_x2, l1_y2 = average_lane(final_lanes[lane1_id])\n",
    "        l2_x1, l2_y1, l2_x2, l2_y2 = average_lane(final_lanes[lane2_id])\n",
    "\n",
    "        return [l1_x1, l1_y1, l1_x2, l1_y2], [l2_x1, l2_y1, l2_x2, l2_y2], lane1_id, lane2_id\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw_lanes(img, lines, color=[255, 0, 0], thickness=7):\n",
    "#     x_bottom_pos = []\n",
    "#     x_upper_pos = []\n",
    "#     x_bottom_neg = []\n",
    "#     x_upper_neg = []\n",
    "\n",
    "#     y_bottom = 540\n",
    "#     y_upper = 315\n",
    "\n",
    "#     slope = 0\n",
    "#     b = 0\n",
    "\n",
    "#     for line in lines:\n",
    "#         for x1,y1,x2,y2 in line:\n",
    "#             # test and filter values to slope\n",
    "#             x1=0\n",
    "#             x2=0\n",
    "#             y1=0\n",
    "#             y2=0\n",
    "\n",
    "#             try:\n",
    "\n",
    "#                 if ((y2-y1)/(x2-x1)) > 0.5 and ((y2-y1)/(x2-x1)) < 0.8:\n",
    "                    \n",
    "#                     slope = ((y2-y1)/(x2-x1))\n",
    "#                     b = y1 - slope*x1\n",
    "                    \n",
    "#                     x_bottom_pos.append((y_bottom - b)/slope)\n",
    "#                     x_upper_pos.append((y_upper - b)/slope)\n",
    "                                        \n",
    "#                 elif ((y2-y1)/(x2-x1)) < -0.5 and ((y2-y1)/(x2-x1)) > -0.8:\n",
    "                \n",
    "#                     slope = ((y2-y1)/(x2-x1))\n",
    "#                     b = y1 - slope*x1\n",
    "                    \n",
    "#                     x_bottom_neg.append((y_bottom - b)/slope)\n",
    "#                     x_upper_neg.append((y_upper - b)/slope)\n",
    "#             except Exception as e:\n",
    "#                 print(str(e))\n",
    "#                 pass\n",
    "\n",
    "#     # a new 2d array with means \n",
    "#     lines_mean = np.array([[int(np.mean(x_bottom_pos)), int(np.mean(y_bottom)), int(np.mean(x_upper_pos)), int(np.mean(y_upper))], \n",
    "#                             [int(np.mean(x_bottom_neg)), int(np.mean(y_bottom)), int(np.mean(x_upper_neg)), int(np.mean(y_upper))]])\n",
    "    \n",
    "#     return lines_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(image):\n",
    "    original_image = image\n",
    "    # convert to gray\n",
    "    processed_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # edge detection\n",
    "    processed_img =  cv2.Canny(processed_img, threshold1 = 200, threshold2=300)\n",
    "    \n",
    "    # apply gauissian blur after edge detection\n",
    "    # because edge detection algorithum drawing the line again\n",
    "    processed_img = cv2.GaussianBlur(processed_img,(5,5),0)\n",
    "    \n",
    "    #returns the array of arrays that contain the lines \n",
    "    vertices = np.array([[10,500],[10,300],[300,200],[500,200],[800,300],[800,500],\n",
    "                         ], np.int32)\n",
    "\n",
    "    processed_img = roi(processed_img, [vertices])\n",
    "\n",
    "    # more info: http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_houghlines/py_houghlines.html\n",
    "    #                                     rho   theta   thresh  min length, max gap:        \n",
    "    lines = cv2.HoughLinesP(processed_img, 1, np.pi/180, 180,      20,       15)\n",
    "    \n",
    "    m1=0\n",
    "    m2=0\n",
    "    try:\n",
    "        l1, l2, m1,m2 = draw_lanes(original_image,lines)\n",
    "        \n",
    "        #find the two final most common slopes\n",
    "        cv2.line(original_image, (l1[0], l1[1]), (l1[2], l1[3]), [0,255,0], 30)\n",
    "        cv2.line(original_image, (l2[0], l2[1]), (l2[2], l2[3]), [0,255,0], 30)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        for coords in lines:\n",
    "            coords = coords[0]\n",
    "            try:\n",
    "                cv2.line(processed_img, (coords[0], coords[1]), (coords[2], coords[3]), [255,0,0], 3)\n",
    "                \n",
    "                \n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    return processed_img,original_image, m1, m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def straight():\n",
    "    ReleaseKey(A)\n",
    "    ReleaseKey(D)\n",
    "\n",
    "\n",
    "def left():\n",
    "\n",
    "    ReleaseKey(D)\n",
    "    PressKey(A) \n",
    "\n",
    "\n",
    "def right():\n",
    "\n",
    "    ReleaseKey(A)\n",
    "    PressKey(D) \n",
    "\n",
    "def slow_accel():\n",
    "    ReleaseKey(W)  \n",
    "\n",
    "\n",
    "def brake():\n",
    "    ReleaseKey(W) \n",
    "    PressKey(S) \n",
    "\n",
    "def accel():\n",
    "    ReleaseKey(S)\n",
    "    PressKey(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in list(range(4))[::-1]:\n",
    "    print(i+1)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     last_time = time.time()\n",
    "#     while True:\n",
    "#         screen =  np.array(ImageGrab.grab(bbox=(0,45,800,650)))\n",
    "#         print('Frame took {} seconds'.format(time.time()-last_time))\n",
    "#         last_time = time.time()\n",
    "#         new_screen,original_image,m1,m2 = process_img(screen)\n",
    "#         # cv2.imshow('window', new_screen)\n",
    "#         cv2.imshow('window2',cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "#         if m1<0 and m2<0:\n",
    "#             right()\n",
    "#         elif m1>0 and m2>0:\n",
    "#             left()\n",
    "#         else:\n",
    "#             straight() \n",
    "\n",
    "#         #cv2.imshow('window',cv2.cvtColor(screen, cv2.COLOR_BGR2RGB))\n",
    "#         if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "#             cv2.destroyAllWindows()\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    last_time = time.time()\n",
    "\n",
    "    while True: \n",
    "        screen =  np.array(ImageGrab.grab(bbox=(0,45,800,650)))\n",
    "        print('Frame took {} seconds'.format(time.time()-last_time))\n",
    "        last_time = time.time()\n",
    "        new_screen,original_image, m1, m2 = process_img(screen)\n",
    "        # cv2.imshow('window', new_screen)\n",
    "        cv2.imshow('window2',cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # if m1<0 and m2<0:\n",
    "        #     right()\n",
    "        # elif m1>0 and m2>0:\n",
    "        #     left()\n",
    "        # else:\n",
    "        #     accel() \n",
    "\n",
    "\n",
    "        #cv2.imshow('window',cv2.cvtColor(screen, cv2.COLOR_BGR2RGB))\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame took 0.09113764762878418 seconds\n",
      "Frame took 0.13300061225891113 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\motoko\\AppData\\Local\\Temp\\ipykernel_7772\\2453974705.py:28: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  m, b = lstsq(A, y_coords)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame took 0.12799906730651855 seconds\n",
      "Frame took 0.13102197647094727 seconds\n",
      "Frame took 0.10100126266479492 seconds\n",
      "Frame took 0.09999966621398926 seconds\n",
      "Frame took 0.1465306282043457 seconds\n",
      "Frame took 0.1210012435913086 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame took 0.10000014305114746 seconds\n",
      "Frame took 0.1329970359802246 seconds\n",
      "Frame took 0.10000324249267578 seconds\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GTA5AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
